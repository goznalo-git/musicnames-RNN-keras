{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music name generator\n",
    "Well here we are. I'm going to find THE best music name, thanks to machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/goznalo/Programming/Python/musicnames/artists.csv\n",
      "/home/goznalo/Programming/Python/musicnames/miusic.ipynb\n",
      "/home/goznalo/Programming/Python/musicnames/clearedlist2.csv\n",
      "/home/goznalo/Programming/Python/musicnames/.git/HEAD\n",
      "/home/goznalo/Programming/Python/musicnames/.git/config\n",
      "/home/goznalo/Programming/Python/musicnames/.git/COMMIT_EDITMSG\n",
      "/home/goznalo/Programming/Python/musicnames/.git/description\n",
      "/home/goznalo/Programming/Python/musicnames/.git/index\n",
      "/home/goznalo/Programming/Python/musicnames/.git/info/exclude\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-push.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-applypatch.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-rebase.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/commit-msg.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/fsmonitor-watchman.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/applypatch-msg.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/post-update.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-merge-commit.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-receive.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/update.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-commit.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/prepare-commit-msg.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/logs/HEAD\n",
      "/home/goznalo/Programming/Python/musicnames/.git/logs/refs/heads/master\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/2a/683c0a5252d10bbfccb4aa06744ed8b3fa20f5\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/06/0564fb228ec1e429c82fd2a2c4a7b70edf0ca5\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/30/903f3079e7d010ee39dc3dc5fdcfd46b477ac5\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/38/e416857a889051f1d0a527a9c77bee68a14fca\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/4a/22a6d50fe774d5d5bc4de81b0c017be38722c1\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/db/1a12e0ce5e70e88e33f7f89dc7030be5b40036\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/b2/2aee76621be4ff9f7f3f877fec858bd4a86aa4\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/66/ab9c069ddac161638bb1aeeeb8c28092e444e2\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/8a/3b2f061eb85260d9ce0b85f4d50166bcc239ed\n",
      "/home/goznalo/Programming/Python/musicnames/.git/refs/heads/master\n",
      "/home/goznalo/Programming/Python/musicnames/.ipynb_checkpoints/miusic-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/goznalo/Programming/Python/musicnames'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "Let's import the data from the kaggle dataset music-artists-popularity, using the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "filename = '/home/goznalo/Programming/Python/musicnames/artists.csv'\n",
    "dataset = pd.read_csv(filename, usecols = [2]) # Obtain the artist name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                  artist_lastfm\n",
       "0                     Coldplay\n",
       "1                    Radiohead\n",
       "2        Red Hot Chili Peppers\n",
       "3                      Rihanna\n",
       "4                       Eminem\n",
       "...                        ...\n",
       "1466078                    NaN\n",
       "1466079                    NaN\n",
       "1466080                    NaN\n",
       "1466081                    NaN\n",
       "1466082                    NaN\n",
       "\n",
       "[1466083 rows x 1 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head # preview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 1\n",
    "We don't want any of the NaN entries, nor duplicate names. We will also convert it to a numpy array for posterior transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.dropna(axis = 0,how = 'any',thresh = None).drop_duplicates(subset=None) #removing NaN's and converting to numpy.\n",
    "names = np.squeeze(np.asarray(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numnames = names.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coldplay'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 2\n",
    "We will now remove all those names using non-standard characters. What I mean by non-standard is all those characters not being latin ones, nor punctuation ones, nor digits, nor spaces. For instance, we will get rid of those using chinese characters or greek letters.\n",
    "\n",
    "We quickly run intro trouble, as the .isalnum() method applied to these non-latin characters returns True. We need to come up with a solution. One way around this is by using the string module. With it, the string.printable characters are those we want to allow in our names, therefore we make a set out of them, which will be used against the names of the database in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E', 'S', 't', 'D', 'z', 'q', 'B', '1', '^', 'f', 'k', '5', 'a', 'Y', 'j', '\"', '2', 'P', 'g', 'u', '|', '(', '*', 'r', '<', 'Z', '7', 'o', 'C', '~', ',', 'd', '0', 'h', ':', '}', 'J', '\\x0b', 'Q', 'V', 'c', '.', '9', 'x', \"'\", '\\x0c', '&', '#', '\\n', 'F', 'X', 'W', 'b', '/', '_', 'U', '3', '8', '4', 'p', 'O', 'K', 'y', '@', 'H', 'l', 'w', 'L', ';', '%', 'i', ']', 'n', '\\\\', 'm', '[', ')', '?', '6', 'G', 'I', 'v', '>', ' ', '\\t', '{', 'T', 's', 'A', 'N', '\\r', '$', 'e', '-', 'M', '=', 'R', '+', '!', '`'}\n"
     ]
    }
   ],
   "source": [
    "validchars = {}\n",
    "validchars[0] = set(string.printable)\n",
    "print(validchars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the loop. An initial approach was creating a new object, a numpy array, to which we would append each valid name, therefore discarding the rest of the names with invalid characters. However, the appending operation makes the algorithm take exponential time of completion. Instead, we can save the index of each invalid word in a list, which we then feed to the np.delete() function to remove those entries of the \"names\" array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid: Beyoncé\n",
      "50000 cases inspected.\n",
      "100000 cases inspected.\n",
      "150000 cases inspected.\n",
      "invalid: Min Ronnersjö\n",
      "200000 cases inspected.\n",
      "250000 cases inspected.\n",
      "300000 cases inspected.\n",
      "invalid: Kaszás Attila\n",
      "350000 cases inspected.\n",
      "400000 cases inspected.\n",
      "invalid: E=MC²\n",
      "450000 cases inspected.\n",
      "500000 cases inspected.\n",
      "invalid: Natércia Maria\n",
      "550000 cases inspected.\n",
      "600000 cases inspected.\n",
      "invalid: 堀米ゆず子\n",
      "650000 cases inspected.\n",
      "700000 cases inspected.\n",
      "invalid: Fütumche!\n",
      "750000 cases inspected.\n",
      "invalid: Léo Clarens\n",
      "800000 cases inspected.\n",
      "850000 cases inspected.\n",
      "invalid: 권기욱\n",
      "900000 cases inspected.\n",
      "invalid: Arbeiter-Chor (Irmler-Männerchor)\n",
      "950000 cases inspected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Beyoncé'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deletelist = {}\n",
    "def deletechars(validcharacters, listofnames):  # We define it as a function, as we will need it in the next steps\n",
    "    #clearlist = np.zeros((1,1))\n",
    "    i = 0 # counts each iteration, i.e. the \n",
    "    j = 0 # counts each invalid word, used to check every now and then that names are correctly discarded.\n",
    "    deletelist = []\n",
    "    for name in listofnames:\n",
    "        if not all(char in validcharacters for char in name):\n",
    "            deletelist.append(i)\n",
    "            if j%10000 == 0:\n",
    "                print(\"invalid: \" + name)\n",
    "            j += 1\n",
    "        #else:\n",
    "        #    clearlist = np.append(clearlist, name[0])\n",
    "        i += 1\n",
    "        if i%50000 == 0:\n",
    "            print(str(i) + \" cases inspected.\")\n",
    "    return deletelist\n",
    "\n",
    "deletelist[0] = deletechars(validchars[0], names)\n",
    "\n",
    "names[deletelist[0][0]] # check that this corresponds to the first invalid word, Beyoncé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coldplay', 'Radiohead', 'Red Hot Chili Peppers', 'Rihanna',\n",
       "       'Eminem', 'The Killers', 'Kanye West', 'Nirvana', 'Muse', 'Queen',\n",
       "       'Foo Fighters', 'Linkin Park', 'Lady Gaga', 'The Rolling Stones',\n",
       "       'Daft Punk', 'Green Day', 'Katy Perry', 'The Beatles', 'Oasis',\n",
       "       'Gorillaz', 'Michael Jackson', 'Maroon 5'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clearedlist = {}\n",
    "clearedlist[0] = np.delete(names, deletelist[0])\n",
    "clearedlist[0][0:22] # Check that Beyoncé has been correctly removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"clearedlist2.csv\", clearedlist[0], delimiter=\",\", fmt='%s') #save the list to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 3: choose your own adventure\n",
    "We will now distinguish four different cases which can be studied, with decreasing complexity. \n",
    "1. The full list, as is.\n",
    "2. The list, having removed punctuation characters and digits.\n",
    "3. The list, having removed both punctuation characters, digits and names with more than two words.\n",
    "4. The list, having removed both punctuation characters, digits and names with more than one word.\n",
    "\n",
    "Case 2 is easy to implement, just applying the previously defined deletechars() function, specifying punctuation characters as invalid (allowing whitespaces). Case 4 is also straightforward to implement, as string.ascii_letters considers any whitespace invalid. Case 3 entails splitting each name using a \"space\" delimiter, and then discarding them lengthwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 3 #change to whichever of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid: Maroon 5\n",
      "50000 cases inspected.\n",
      "100000 cases inspected.\n",
      "invalid: Mother Mallard's Portable Masterpiece Company\n",
      "150000 cases inspected.\n",
      "200000 cases inspected.\n",
      "invalid: James T & The Workers\n",
      "250000 cases inspected.\n",
      "invalid: Nishat Khan, Javed Ali & Shilpa Rao\n",
      "300000 cases inspected.\n",
      "350000 cases inspected.\n",
      "invalid: Josh Rennie-Hynes\n",
      "400000 cases inspected.\n",
      "invalid: Orphee's Cry\n",
      "450000 cases inspected.\n",
      "500000 cases inspected.\n",
      "invalid: King's Kaleidoscope\n",
      "550000 cases inspected.\n",
      "invalid: Benny Goodman & Friends\n",
      "600000 cases inspected.\n",
      "invalid: Santa Claus & Singing Xmas\n",
      "650000 cases inspected.\n",
      "700000 cases inspected.\n",
      "invalid: Amtlich!\n",
      "750000 cases inspected.\n",
      "invalid: 3 Years 3 Dats\n",
      "800000 cases inspected.\n",
      "invalid: Dr. Marcus Cosby & The Wheeler Avenue Baptist Church Mass Choir\n",
      "850000 cases inspected.\n",
      "invalid: Red Hot Chili Peppers\n",
      "50000 cases inspected (lengthwise).\n",
      "invalid: Hampton Hawes Trio\n",
      "100000 cases inspected (lengthwise).\n",
      "invalid: Scruffy the Cat\n",
      "150000 cases inspected (lengthwise).\n",
      "200000 cases inspected (lengthwise).\n",
      "invalid: Mads Emil Nielsen\n",
      "250000 cases inspected (lengthwise).\n",
      "invalid: I come from Pop\n",
      "300000 cases inspected (lengthwise).\n",
      "invalid: Out of Our Depth\n",
      "350000 cases inspected (lengthwise).\n",
      "invalid: Flor del Pueblo\n",
      "400000 cases inspected (lengthwise).\n",
      "invalid: Santa Fe Desert Chorale\n",
      "450000 cases inspected (lengthwise).\n",
      "500000 cases inspected (lengthwise).\n",
      "invalid: Paul Plimley Trio\n",
      "550000 cases inspected (lengthwise).\n",
      "invalid: The Lakeside Singers\n",
      "600000 cases inspected (lengthwise).\n",
      "invalid: Rotterdam Philharmonic Wind Ensemble\n",
      "650000 cases inspected (lengthwise).\n",
      "700000 cases inspected (lengthwise).\n",
      "invalid: Michele tale di bella\n",
      "['Coldplay' 'Radiohead' 'Rihanna' 'Eminem' 'The Killers' 'Kanye West'\n",
      " 'Nirvana' 'Muse' 'Queen' 'Foo Fighters' 'Linkin Park' 'Lady Gaga'\n",
      " 'Daft Punk' 'Green Day' 'Katy Perry' 'The Beatles' 'Oasis' 'Gorillaz'\n",
      " 'Michael Jackson' 'Arctic Monkeys' 'Drake' 'David Bowie']\n"
     ]
    }
   ],
   "source": [
    "validchars[1] = set(string.ascii_letters).union(\" \")\n",
    "validchars[2] = set(string.ascii_letters).union(\" \") #we won't use it here, but we will count the characters with this.\n",
    "validchars[3] = set(string.ascii_letters)\n",
    "    \n",
    "if (case == 2 or case == 3 or case == 4):\n",
    "    deletelist[1] = deletechars(validchars[1], clearedlist[0])\n",
    "    clearedlist[1] = np.delete(clearedlist[0], deletelist[1])\n",
    "    \n",
    "    if (case == 3 or case == 4): #as the function above, but indexing based on the length of string.split()\n",
    "        i = 0 \n",
    "        j = 0 \n",
    "        deletelist[2] = []\n",
    "        for name in clearedlist[1]:\n",
    "            if len(name.split()) > 2:\n",
    "                deletelist[2].append(i)\n",
    "                if j%10000 == 0:\n",
    "                    print(\"invalid: \" + name)\n",
    "                j += 1\n",
    "            i += 1\n",
    "            if i%50000 == 0:\n",
    "                print(str(i) + \" cases inspected (lengthwise).\")\n",
    "        clearedlist[2] = np.delete(clearedlist[1], deletelist[2])\n",
    "        \n",
    "        if case == 4: # string.ascii_letters considers whitespaces as invalid.\n",
    "            deletelist[3] = deletechars(validchars[3], clearedlist[2])\n",
    "            clearedlist[3] = np.delete(clearedlist[2], deletelist[3])\n",
    "\n",
    "\n",
    "print(clearedlist[2][0:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more pre-processing, I guess\n",
    "\n",
    "Now that we have our desired array of names, we need to prepare them for being inputted to a neural network. There are several steps to be taken: first, we will make all names lowercase, so as to use a dimensionally smaller encoding. Then, making use of the char_to_index dictionary and the keras.utils.to_categorical() function, we will create our one-hot vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = len(clearedlist[case-1])\n",
    "for i in range(datasize):\n",
    "    clearedlist[case-1][i] = clearedlist[case-1][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(dict.fromkeys([char.lower() for char in validchars[case-1]])))\n",
    "numchars = len(chars)\n",
    "char_to_index = { ch:ix for ix, ch in enumerate(chars)} #assigns numbers to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-da7b24b70538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclearedlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#make a 27-dimensional one-hot vector out of each character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnametocateg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlett\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlett\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnametocateg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# shift one unit to the left. if list: a.insert(0,a.pop())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msplitlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnametocateg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "splitlist = []\n",
    "outlist = []\n",
    "for name in clearedlist[case-1]: #make a 27-dimensional one-hot vector out of each character\n",
    "    nametocateg = to_categorical([char_to_index[lett] for lett in name], num_classes = numchars)\n",
    "    outname = [np.append(arr,0.) for arr in np.roll(nametocateg,-1)[:-1]] # shift one unit to the left. if list: a.insert(0,a.pop())\n",
    "    splitlist.append(nametocateg)\n",
    "    outlist.append(outname)\n",
    "    \n",
    "splitlist[0] # c o l d p l a y, categorical (one-hot) version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
