{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music name generator\n",
    "Well here we are. I'm going to find THE best music name, thanks to machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/goznalo/Programming/Python/musicnames/artists.csv\n",
      "/home/goznalo/Programming/Python/musicnames/clearedlist3.csv\n",
      "/home/goznalo/Programming/Python/musicnames/miusic.ipynb\n",
      "/home/goznalo/Programming/Python/musicnames/clearedlist1.csv\n",
      "/home/goznalo/Programming/Python/musicnames/clearedlist2.csv\n",
      "/home/goznalo/Programming/Python/musicnames/.ipynb_checkpoints/miusic-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/goznalo/Programming/Python/musicnames'):\n",
    "    for filename in filenames:\n",
    "        if \".git\" not in dirname:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "Let's import the data from the kaggle dataset music-artists-popularity, using the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "filename = '/home/goznalo/Programming/Python/musicnames/artists.csv'\n",
    "dataset = pd.read_csv(filename, usecols = [2], dtype=str) # Obtain the artist name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                  artist_lastfm\n",
       "0                     Coldplay\n",
       "1                    Radiohead\n",
       "2        Red Hot Chili Peppers\n",
       "3                      Rihanna\n",
       "4                       Eminem\n",
       "...                        ...\n",
       "1466078                    NaN\n",
       "1466079                    NaN\n",
       "1466080                    NaN\n",
       "1466081                    NaN\n",
       "1466082                    NaN\n",
       "\n",
       "[1466083 rows x 1 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head # preview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 1\n",
    "We don't want any of the NaN entries, nor duplicate names. We will also convert it to a numpy array for posterior transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.dropna(axis = 0,how = 'any',thresh = None).drop_duplicates(subset=None) #removing NaN's and converting to numpy.\n",
    "names = np.squeeze(np.asarray(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957812"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coldplay'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 2\n",
    "We will now remove all those names using non-standard characters. What I mean by non-standard is all those characters not being latin ones, nor punctuation ones, nor digits, nor spaces. For instance, we will get rid of those using chinese characters or greek letters.\n",
    "\n",
    "If we try applying the .isalnum() method, we quickly run into trouble as these non-latin characters return True. We need to come up with a solution. One way around this is by using the string module. With it, the string.printable characters are those we want to allow in our names, therefore we make a set out of them, which will be used against the names of the database in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'>', 't', 'U', 'a', 'w', '4', 'H', '(', 'X', '&', 'o', '`', '?', '2', 'p', '%', 'L', '!', '-', ';', '8', 'v', '9', 'k', '@', '{', 'S', 'h', '~', '*', '^', 'J', '+', 'W', ')', '\\r', '\\t', '=', 'V', 'K', 's', 'b', 'D', 'I', \"'\", 'm', '\\\\', ':', 'x', '|', 'j', ',', 'r', '\"', 'A', ']', '}', '[', 'z', 'T', 'f', '.', 'E', '6', 'Y', 'n', 'M', 'c', 'F', '$', ' ', '0', '7', '<', '#', '1', '\\n', 'u', 'Q', 'C', '_', 'R', 'l', 'O', 'N', '5', '\\x0c', 'i', 'y', 'B', 'Z', 'e', '\\x0b', 'G', 'g', 'd', '3', '/', 'q', 'P'}\n"
     ]
    }
   ],
   "source": [
    "validchars = {}\n",
    "validchars[0] = set(string.printable)\n",
    "print(validchars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the loop. An initial approach was creating a new object, a numpy array, to which we would append each valid name, therefore discarding the rest of the names with invalid characters. However, the appending operation makes the algorithm take exponential time of completion. Instead, we can save the index of each invalid word in a list, which we then feed to the np.delete() function to remove those entries of the \"names\" array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearedlist = {}\n",
    "def deletechars(validcharacters, listofnames, verbose=False):  # We define it within a function, as we will need it in the next steps\n",
    "    i = 0 # counts each iteration\n",
    "    j = 0 # counts each invalid word\n",
    "    deletelist= []\n",
    "    for name in listofnames:\n",
    "        if not all(char in validcharacters for char in name):\n",
    "            deletelist.append(i)\n",
    "            if j%10000 == 0 and verbose:\n",
    "                print(\"invalid: \" + name)\n",
    "            j += 1\n",
    "        i += 1\n",
    "        if i%50000 == 0 and verbose:\n",
    "            print(str(i) + \" cases inspected.\")\n",
    "    return np.delete(listofnames, deletelist)\n",
    "\n",
    "clearedlist[0] = deletechars(validchars[0], names) #by default, verbose = False (no output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Coldplay', 'Radiohead', 'Red Hot Chili Peppers', 'Rihanna',\n",
       "       'Eminem', 'The Killers', 'Kanye West', 'Nirvana', 'Muse', 'Queen',\n",
       "       'Foo Fighters', 'Linkin Park', 'Lady Gaga', 'The Rolling Stones',\n",
       "       'Daft Punk', 'Green Day', 'Katy Perry', 'The Beatles', 'Oasis',\n",
       "       'Gorillaz', 'Michael Jackson', 'Maroon 5'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clearedlist[0][0:22] # Check that BeyoncÃ© has been correctly removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"clearedlist1.csv\", clearedlist[0], delimiter=\",\", fmt='%s') #save the list to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 3: choose your own adventure\n",
    "We will now distinguish four different cases which can be studied, with decreasing complexity. \n",
    "1. The full list, as is.\n",
    "2. The list, having removed punctuation characters and digits.\n",
    "3. The list, having removed both punctuation characters, digits and names with more than two words.\n",
    "4. The list, having removed both punctuation characters, digits and names with more than one word.\n",
    "\n",
    "Case 2 is easy to implement, just applying the previously defined deletechars() function, specifying punctuation characters as invalid (allowing whitespaces). Case 4 is also straightforward to implement, as string.ascii_letters considers any whitespace invalid. Case 3 entails splitting each name using a \"space\" delimiter, and then discarding them lengthwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 3 #change to whichever of the above\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(957812, 861756, 743526, 626581, 0)\n",
      "['Coldplay' 'Radiohead' 'Rihanna' 'Eminem' 'The Killers' 'Kanye West'\n",
      " 'Nirvana' 'Muse' 'Queen' 'Foo Fighters' 'Linkin Park' 'Lady Gaga'\n",
      " 'Daft Punk' 'Green Day' 'Katy Perry' 'The Beatles' 'Oasis' 'Gorillaz'\n",
      " 'Michael Jackson' 'Arctic Monkeys' 'Drake' 'David Bowie']\n"
     ]
    }
   ],
   "source": [
    "validchars[1] = set(string.ascii_letters).union(\" \")\n",
    "validchars[2] = set(string.ascii_letters).union(\" \") #we won't use it here, but we will count the characters with this.\n",
    "validchars[3] = set(string.ascii_letters)\n",
    "\n",
    "clearedlist[1] = []\n",
    "clearedlist[2] = []\n",
    "clearedlist[3] = []\n",
    "\n",
    "if (case == 2 or case == 3 or case == 4):\n",
    "    clearedlist[1] = deletechars(validchars[1], clearedlist[0])\n",
    "    np.savetxt(\"clearedlist2.csv\", clearedlist[1], delimiter=\",\", fmt='%s')\n",
    "    \n",
    "    if (case == 3 or case == 4): #as the function above, but indexing based on the length of string.split()\n",
    "        i = 0 \n",
    "        j = 0 \n",
    "        deletelist = []\n",
    "        for name in clearedlist[1]:\n",
    "            if len(name.split()) > 2:\n",
    "                deletelist.append(i)\n",
    "                if j%10000 == 0 and verbose:\n",
    "                    print(\"invalid: \" + name)\n",
    "                j += 1\n",
    "            i += 1\n",
    "            if i%50000 == 0 and verbose:\n",
    "                print(str(i) + \" cases inspected (lengthwise).\")\n",
    "        clearedlist[2] = np.delete(clearedlist[1], deletelist)\n",
    "        np.savetxt(\"clearedlist3.csv\", clearedlist[2], delimiter=\",\", fmt='%s') \n",
    "        \n",
    "        if case == 4: # string.ascii_letters considers whitespaces as invalid.\n",
    "            clearedlist[3] = deletechars(validchars[3], clearedlist[2])\n",
    "            np.savetxt(\"clearedlist4.csv\", clearedlist[3], delimiter=\",\", fmt='%s')\n",
    "\n",
    "print((len(names), len(clearedlist[0]), len(clearedlist[1]), len(clearedlist[2]), len(clearedlist[3])))\n",
    "print(clearedlist[2][0:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more pre-processing, I guess\n",
    "\n",
    "Now that we have our desired array of names, we need to prepare them for being inputted to a neural network. There are several steps to be taken: first, \n",
    "we will append to each name a \"\\n\" character: this will be our end-of-name character. We will later make all names lowercase, so as to use a dimensionally smaller encoding. Then, making use of the char_to_index dictionary and the keras.utils.to_categorical() function, we will create our one-hot vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clearedlist[case-1] #definitive list of names\n",
    "m = len(data) #training examples\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i] + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coldplay\\n\\n', 'Radiohead\\n\\n', 'Rihanna\\n\\n', ...,\n",
       "       'wilkwceniu\\n\\n', 'xHoods Upx\\n\\n', 'yellow Labradore\\n\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clearedlist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(m):\n",
    "    data[i] = data[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(dict.fromkeys([char.lower() for char in validchars[case-1]])))\n",
    "numchars = len(chars)\n",
    "char_to_index = { ch:ix for ix, ch in enumerate(chars)} #assigns numbers to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
