{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music name generator\n",
    "Well here we are. I'm going to find THE best music name, thanks to machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/goznalo/Programming/Python/musicnames/artists.csv\n",
      "/home/goznalo/Programming/Python/musicnames/miusic.ipynb\n",
      "/home/goznalo/Programming/Python/musicnames/clearedlist2.csv\n",
      "/home/goznalo/Programming/Python/musicnames/.git/HEAD\n",
      "/home/goznalo/Programming/Python/musicnames/.git/config\n",
      "/home/goznalo/Programming/Python/musicnames/.git/COMMIT_EDITMSG\n",
      "/home/goznalo/Programming/Python/musicnames/.git/description\n",
      "/home/goznalo/Programming/Python/musicnames/.git/index\n",
      "/home/goznalo/Programming/Python/musicnames/.git/info/exclude\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-push.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-applypatch.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-rebase.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/commit-msg.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/fsmonitor-watchman.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/applypatch-msg.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/post-update.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-merge-commit.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-receive.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/update.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/pre-commit.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/hooks/prepare-commit-msg.sample\n",
      "/home/goznalo/Programming/Python/musicnames/.git/logs/HEAD\n",
      "/home/goznalo/Programming/Python/musicnames/.git/logs/refs/heads/master\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/29/6366b56b0ab0c26de64aeaa4562f890af53bb0\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/2a/683c0a5252d10bbfccb4aa06744ed8b3fa20f5\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/a7/c158a4a5a16ed50b176514ff6d1d5b759ab4b4\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/d5/5019895146088aa79e116d90c7b5cf768a4a95\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/bc/22b980e3acffbadfdca32f1193f2445f055cd6\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/06/0564fb228ec1e429c82fd2a2c4a7b70edf0ca5\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/6f/53f82fa32760a7a7b78318bd3d55bf446319f7\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/30/903f3079e7d010ee39dc3dc5fdcfd46b477ac5\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/38/e416857a889051f1d0a527a9c77bee68a14fca\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/4a/22a6d50fe774d5d5bc4de81b0c017be38722c1\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/28/53cd77a3c327fca9baef110fa5dbf9a8d179af\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/db/1a12e0ce5e70e88e33f7f89dc7030be5b40036\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/b2/2aee76621be4ff9f7f3f877fec858bd4a86aa4\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/66/ab9c069ddac161638bb1aeeeb8c28092e444e2\n",
      "/home/goznalo/Programming/Python/musicnames/.git/objects/8a/3b2f061eb85260d9ce0b85f4d50166bcc239ed\n",
      "/home/goznalo/Programming/Python/musicnames/.git/refs/heads/master\n",
      "/home/goznalo/Programming/Python/musicnames/.ipynb_checkpoints/miusic-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/goznalo/Programming/Python/musicnames'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "Let's import the data from the kaggle dataset music-artists-popularity, using the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "filename = '/home/goznalo/Programming/Python/musicnames/artists.csv'\n",
    "dataset = pd.read_csv(filename, usecols = [2]) # Obtain the artist name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                  artist_lastfm\n",
       "0                     Coldplay\n",
       "1                    Radiohead\n",
       "2        Red Hot Chili Peppers\n",
       "3                      Rihanna\n",
       "4                       Eminem\n",
       "...                        ...\n",
       "1466078                    NaN\n",
       "1466079                    NaN\n",
       "1466080                    NaN\n",
       "1466081                    NaN\n",
       "1466082                    NaN\n",
       "\n",
       "[1466083 rows x 1 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head # preview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 1\n",
    "We don't want any of the NaN entries, nor duplicate names. We will also convert it to a numpy array for posterior transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.dropna(axis = 0,how = 'any',thresh = None).drop_duplicates(subset=None) #removing NaN's and converting to numpy.\n",
    "names = np.squeeze(np.asarray(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numnames = names.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coldplay'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 2\n",
    "We will now remove all those names using non-standard characters. What I mean by non-standard is all those characters not being latin ones, nor punctuation ones, nor digits, nor spaces. For instance, we will get rid of those using chinese characters or greek letters.\n",
    "\n",
    "We quickly run intro trouble, as the .isalnum() method applied to these non-latin characters returns True. We need to come up with a solution. One way around this is by using the string module. With it, the string.printable characters are those we want to allow in our names, therefore we make a set out of them, which will be used against the names of the database in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E', 'S', 't', 'D', 'z', 'q', 'B', '1', '^', 'f', 'k', '5', 'a', 'Y', 'j', '\"', '2', 'P', 'g', 'u', '|', '(', '*', 'r', '<', 'Z', '7', 'o', 'C', '~', ',', 'd', '0', 'h', ':', '}', 'J', '\\x0b', 'Q', 'V', 'c', '.', '9', 'x', \"'\", '\\x0c', '&', '#', '\\n', 'F', 'X', 'W', 'b', '/', '_', 'U', '3', '8', '4', 'p', 'O', 'K', 'y', '@', 'H', 'l', 'w', 'L', ';', '%', 'i', ']', 'n', '\\\\', 'm', '[', ')', '?', '6', 'G', 'I', 'v', '>', ' ', '\\t', '{', 'T', 's', 'A', 'N', '\\r', '$', 'e', '-', 'M', '=', 'R', '+', '!', '`'}\n"
     ]
    }
   ],
   "source": [
    "validchars = {}\n",
    "validchars[0] = set(string.printable)\n",
    "print(validchars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the loop. An initial approach was creating a new object, a numpy array, to which we would append each valid name, therefore discarding the rest of the names with invalid characters. However, the appending operation makes the algorithm take exponential time of completion. Instead, we can save the index of each invalid word in a list, which we then feed to the np.delete() function to remove those entries of the \"names\" array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearedlist = {}\n",
    "def deletechars(validcharacters, listofnames, verbose=False):  # We define it as a function, as we will need it in the next steps\n",
    "    i = 0 # counts each iteration\n",
    "    j = 0 # counts each invalid word\n",
    "    deletelist = []\n",
    "    for name in listofnames:\n",
    "        if not all(char in validcharacters for char in name):\n",
    "            deletelist.append(i)\n",
    "            if j%10000 == 0 and verbose:\n",
    "                print(\"invalid: \" + name)\n",
    "            j += 1\n",
    "        i += 1\n",
    "        if i%50000 == 0 and verbose:\n",
    "            print(str(i) + \" cases inspected.\")\n",
    "    return np.delete(names, deletelist)\n",
    "\n",
    "clearedlist[0] = deletechars(validchars[0], names) #by default, verbose = False (no output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coldplay', 'Radiohead', 'Red Hot Chili Peppers', 'Rihanna',\n",
       "       'Eminem', 'The Killers', 'Kanye West', 'Nirvana', 'Muse', 'Queen',\n",
       "       'Foo Fighters', 'Linkin Park', 'Lady Gaga', 'The Rolling Stones',\n",
       "       'Daft Punk', 'Green Day', 'Katy Perry', 'The Beatles', 'Oasis',\n",
       "       'Gorillaz', 'Michael Jackson', 'Maroon 5'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clearedlist[0][0:22] # Check that Beyoncé has been correctly removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"clearedlist1.csv\", clearedlist[0], delimiter=\",\", fmt='%s') #save the list to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing, part 3: choose your own adventure\n",
    "We will now distinguish four different cases which can be studied, with decreasing complexity. \n",
    "1. The full list, as is.\n",
    "2. The list, having removed punctuation characters and digits.\n",
    "3. The list, having removed both punctuation characters, digits and names with more than two words.\n",
    "4. The list, having removed both punctuation characters, digits and names with more than one word.\n",
    "\n",
    "Case 2 is easy to implement, just applying the previously defined deletechars() function, specifying punctuation characters as invalid (allowing whitespaces). Case 4 is also straightforward to implement, as string.ascii_letters considers any whitespace invalid. Case 3 entails splitting each name using a \"space\" delimiter, and then discarding them lengthwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 3 #change to whichever of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid: Red Hot Chili Peppers\n",
      "50000 cases inspected (lengthwise).\n",
      "invalid: Monkey To Millionaire\n",
      "100000 cases inspected (lengthwise).\n",
      "invalid: Mono Electric Orchestra\n",
      "150000 cases inspected (lengthwise).\n",
      "invalid: Easy & Center of the Universe\n",
      "200000 cases inspected (lengthwise).\n",
      "invalid: St. Gun Khin May\n",
      "250000 cases inspected (lengthwise).\n",
      "invalid: Thirty Seconds Until Armageddon\n",
      "300000 cases inspected (lengthwise).\n",
      "invalid: Derrick & Tee\n",
      "350000 cases inspected (lengthwise).\n",
      "invalid: The Insect Explosion\n",
      "400000 cases inspected (lengthwise).\n",
      "invalid: The Raisin Pickers\n",
      "450000 cases inspected (lengthwise).\n",
      "invalid: Niek en Danny\n",
      "500000 cases inspected (lengthwise).\n",
      "invalid: Sioux Red Indian Tribes\n",
      "550000 cases inspected (lengthwise).\n",
      "invalid: Sabre & Prezident Brown\n",
      "600000 cases inspected (lengthwise).\n",
      "invalid: Acto De Venganza\n",
      "650000 cases inspected (lengthwise).\n",
      "invalid: 方正 & 許不了\n",
      "700000 cases inspected (lengthwise).\n",
      "invalid: Tater Family Travelling Circus\n",
      "750000 cases inspected (lengthwise).\n",
      "invalid: Jack Benny and Frank Knight\n",
      "800000 cases inspected (lengthwise).\n",
      "invalid: DJ Pila, DJ Scientist and DJ Pryde\n",
      "invalid: Saskia Reese, Lara Zöller & Jana Treute\n",
      "['Coldplay' 'Radiohead' 'Rihanna' 'Eminem' 'The Killers' 'Kanye West'\n",
      " 'Nirvana' 'Muse' 'Queen' 'Foo Fighters' 'Linkin Park' 'Lady Gaga'\n",
      " 'Daft Punk' 'Green Day' 'Katy Perry' 'The Beatles' 'Oasis' 'Gorillaz'\n",
      " 'Beyoncé' 'Maroon 5' 'Arctic Monkeys' 'U2']\n"
     ]
    }
   ],
   "source": [
    "validchars[1] = set(string.ascii_letters).union(\" \")\n",
    "validchars[2] = set(string.ascii_letters).union(\" \") #we won't use it here, but we will count the characters with this.\n",
    "validchars[3] = set(string.ascii_letters)\n",
    "    \n",
    "if (case == 2 or case == 3 or case == 4):\n",
    "    clearedlist[1] = deletechars(validchars[1], clearedlist[0])\n",
    "    np.savetxt(\"clearedlist2.csv\", clearedlist[1], delimiter=\",\", fmt='%s') \n",
    "    \n",
    "    if (case == 3 or case == 4): #as the function above, but indexing based on the length of string.split()\n",
    "        i = 0 \n",
    "        j = 0 \n",
    "        deletelist[2] = []\n",
    "        for name in clearedlist[1]:\n",
    "            if len(name.split()) > 2:\n",
    "                deletelist[2].append(i)\n",
    "                if j%10000 == 0:\n",
    "                    print(\"invalid: \" + name)\n",
    "                j += 1\n",
    "            i += 1\n",
    "            if i%50000 == 0:\n",
    "                print(str(i) + \" cases inspected (lengthwise).\")\n",
    "        clearedlist[2] = np.delete(clearedlist[1], deletelist[2])\n",
    "        np.savetxt(\"clearedlist3.csv\", clearedlist[2], delimiter=\",\", fmt='%s') \n",
    "        \n",
    "        if case == 4: # string.ascii_letters considers whitespaces as invalid.\n",
    "            clearedlist[3] = deletechars(validchars[3], clearedlist[2])\n",
    "            np.savetxt(\"clearedlist4.csv\", clearedlist[3], delimiter=\",\", fmt='%s')\n",
    "\n",
    "\n",
    "print(clearedlist[2][0:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more pre-processing, I guess\n",
    "\n",
    "Now that we have our desired array of names, we need to prepare them for being inputted to a neural network. There are several steps to be taken: first, we will make all names lowercase, so as to use a dimensionally smaller encoding. Then, making use of the char_to_index dictionary and the keras.utils.to_categorical() function, we will create our one-hot vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = len(clearedlist[case-1])\n",
    "for i in range(datasize):\n",
    "    clearedlist[case-1][i] = clearedlist[case-1][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(dict.fromkeys([char.lower() for char in validchars[case-1]])))\n",
    "numchars = len(chars)\n",
    "char_to_index = { ch:ix for ix, ch in enumerate(chars)} #assigns numbers to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
